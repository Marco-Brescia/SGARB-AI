# SGARB-AI

![SGARB-AI](interface/static/images/logo_2su1_w.png)

## Gruppo

Il progetto Ã¨ stato realizzato dal gruppo **Symposium**.

### Componenti del gruppo:
- ðŸ§‘â€ðŸ’» [**Giuseppe Gambardella**](https://github.com/giuseppegambardella)
- ðŸ§‘â€ðŸ’» [**Marco Brescia**](https://github.com/Marco-Brescia)
- ðŸ§‘â€ðŸ’» [**Francesco Faiella**](https://github.com/FaiellaFrancesco)


## Indice
1. ðŸ“ [Introduzione](#-introduzione)
2. ðŸ“¦ [Requisiti](#-requisiti)
3. ðŸ“¦ [Gestione modelli con Git LFS](#-gestione-dei-modelli-con-git-lfs)
4. ðŸš€ [Come replicare il progetto](#-come-replicare-il-progetto)
    - ðŸ—‚ï¸ [Reperire il dataset](#-reperire-il-dataset)
    - ðŸ—‘ï¸ [Eliminazione cartelle non utilizzate](#-eliminazione-cartelle-non-utilizzate)
    - ðŸ”¢ [Selezione immagini con Coseno Distribuito per la riduzione del dataset per il training](#-selezione-immagini-con-coseno-distribuito-per-la-riduzione-del-dataset-per-il-training)
    - ðŸ“Š [Creazione del dataset per il training](#-creazione-del-dataset-per-il-training)
    - ðŸ–¼ï¸ [Preprocessing delle immagini](#-preprocessing-delle-immagini)
    - ðŸ§ª [Creazione del TestSet](#-creazione-del-testset)
    - ðŸ‹ï¸â€â™‚ï¸ [Training del modello](#-training-del-modello)
    - ðŸ”„ [Ordine di esecuzione degli script](#-ordine-di-esecuzione-degli-script)
    - ðŸŒ [Esecuzione dell'interfaccia](#-esecuzione-dellinterfaccia)

## ðŸ“ Introduzione

Il progetto **SGARB-AI** Ã¨ stato sviluppato come parte del corso di **Intelligenza Artificiale** presso l'**UniversitÃ  degli Studi di Salerno**, nell'anno accademico **2024-2025**. L'obiettivo principale di questo progetto Ã¨ l'implementazione di un sistema di riconoscimento delle immagini, utilizzando tecniche di deep learning, per distinguere tra opere d'arte reali e arte generata tramite algoritmi di intelligenza artificiale.

Attraverso l'analisi e il confronto di immagini provenienti da due categorie principali â€” **REALE** e **IA** â€” il progetto mira a sviluppare un modello in grado di riconoscere le differenze tra arte prodotta da esseri umani e quella creata da algoritmi avanzati, con particolare attenzione alla riduzione del dataset e all'ottimizzazione del modello per una classificazione accurata.

In particolare, il progetto si Ã¨ focalizzato maggiormente sul riconoscimento e la classificazione accurata della classe **IA**, con l'intento di migliorare la capacitÃ  del modello di identificare le immagini generate tramite intelligenza artificiale, riducendo al minimo i falsi negativi in questa categoria.


# ðŸ“¦ Requisiti

- Anaconda, una piattaforma per la gestione di ambienti e pacchetti Python, utile per data science, machine learning e progetti scientifici.

> **Nota:** Se Anaconda Ã¨ giÃ  installato e il percorso Ã¨ correttamente aggiunto alle variabili di ambiente, gli script procederanno esclusivamente con l'installazione dell'ambiente virtuale.

- In alternativa, puoi scaricare e installare manualmente Anaconda da questo link, scegliendo la versione adatta al tuo sistema operativo.
    - [Anaconda](https://repo.anaconda.com/archive)



## MacOS

1. Apri il terminale.
2. Naviga nella cartella `ambienti` del progetto:
    ```bash
    cd /percorso/del/progetto/ambienti
    ```
3. Esegui lo script di installazione per macOS:
    ```bash
    ./MacOSenv.sh
    ```
4. Segui le istruzioni nel terminale per completare l'installazione dell'ambiente.
5. Nel caso in cui il terminale non riconosca lo script come eseguibile, esegui il seguente comando:
    ```bash
    chmod +x MacOSenv.sh
    ```
    E ripeti il passaggio 3.
6. Non chiudere il terminale finchÃ© l'installazione non Ã¨ completata.

## Windows

1. Apri il prompt dei comandi (CMD) come amministratore.
2. Naviga nella cartella `ambienti` del progetto:
    ```cmd
    cd \percorso\del\progetto\ambienti
    ```
3. Esegui lo script di installazione per Windows:
    ```bat
    WindowsEnv.bat
    ```
4. Segui le istruzioni nel prompt dei comandi per completare l'installazione dell'ambiente.

## Installazione esclusiva dell'ambiente virtuale senza Anaconda

1. Installa Anaconda dal link fornito sopra in modo che il percorso sia aggiunto alle variabili di ambiente.
2. Avvia lo script fornito sopra per importare l'ambiente virtuale:
    - MacOS: `MacOSenv.sh`
    - Windows: `WindowsEnv.bat`
3. Segui le istruzioni nel terminale o nel prompt dei comandi per completare l'installazione dell'ambiente.
4. Non chiudere il terminale o il prompt dei comandi finchÃ© l'installazione non Ã¨ completata.
5. Se l'installazione Ã¨ completata, puoi chiudere il terminale o il prompt dei comandi.

## ðŸ“¦ Gestione dei modelli con Git LFS
>**Nota:** Nel progetto sono presenti piÃ¹ modelli, ogni modello rappresenta una fase di training diversa.
> In ordine cronologico:
> 1. New - Primo modello
> 2. CosenoDistribuito - Modello addestrato con immagini selezionate tramite la distanza coseno 
> 3. f2_0 - Modello addestrato come CosenoDistribuito ma con funzione di loss modificata, peso 2 per la classe AI (0)
> 4. f1_5 - Modello addestrato come f2_0 ma con peso differente (1.5)
> 5. Specificity - Modello finale
> 
> Si consiglia di pullare solo Specificity 
1. File interessati: file con estensione `.h5`
2. Se aprendo un file .h5 trovi il seguente contenuto:
```
  version https://git-lfs.github.com/spec/v1
  oid sha256:9c5d3e1a842c7b51e03a1a6bd2d3b8499a7d543e71916a67f3f3280e3b7d9e7b
  size 10485760
```
Significa che il file Ã¨ un segnaposto e il contenuto reale non Ã¨ ancora stato scaricato.
3. Per scaricare i file completi, utilizza il seguente comando:

 ```bash
  git lfs install
  git lfs pull
 ```

- Questo comando scaricherÃ  i file reali dal server remoto, rendendoli pronti per lâ€™uso.


In alcuni casi, i file vengono scaricati automaticamente durante il git clone o il git pull. Tuttavia, se trovi file .h5 che appaiono come segnaposto (con il contenuto testuale mostrato sopra), esegui manualmente git lfs pull per ottenere i dati completi.
>**Nota:** Git LFS Ã¨ giÃ  installato nellâ€™ambiente di lavoro preconfigurato, quindi non Ã¨ necessario installarlo manualmente.


# ðŸš€ Come replicare il progetto
> **Note:** Per chi preferisse non replicare interamente il progetto e desiderasse saltare la fase di preprocessing dei dati, il dataset Ã¨ giÃ  disponibile su GitHub nella cartella `DatasetTrainingDistanzaCoseno_Distribuito(Processed)`.

## ðŸ—‚ï¸ Reperire il dataset

1. Scaricare il dataset dal seguente link:
    - [Dataset](https://www.kaggle.com/datasets/ravidussilva/real-ai-art)
    - Scaricato il dataset estraetelo in una cartella

## ðŸ—‘ï¸ Eliminazione cartelle non utilizzate
1. Aprendo la cartella del dataset, la struttura sara' la seguente:
    ```
    real-ai-art
      â”œâ”€â”€ train
      â”‚   â”œâ”€â”€ AI_LD_art_nouveau
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ AI_LD_baroque
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ AI_SD_art_nouveau
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”œâ”€â”€ AI_SD_baroque
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ art_nouveau
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ baroque
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”œâ”€â”€ test
      â”‚   â”œâ”€â”€ AI_LD_art_nouveau
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ AI_LD_baroque
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ AI_SD_art_nouveau
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”œâ”€â”€ AI_SD_baroque
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ art_nouveau
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
      â”‚   â”œâ”€â”€ baroque
      â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
      â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
      â”‚   â”‚   â”‚
      â”‚   â”‚   â”œâ”€â”€ ecc...
    ```
2. Eliminare le cartelle che hanno il prefisso `AI_SD` in entrambe le cartelle `train` e `test` poichÃ© non sono utilizzate per il progetto.

## ðŸ”¢ Selezione immagini con Coseno Distribuito per la riduzione del dataset per il training
1. File interessato: `SelezioneImmaginiCosenoDistribuito.py`
2. Puntare il percorso del dataset nella variabile `source_dir`, aggiungere alle variabili `output_dir` e `grafici_dir` i path delle cartelle di destinazione.
   - Esempio:
    ```python
    source_dir = Path("percorso/del/dataset/train ES: ../../real-ai-art/train") # Cartella contenente il dataset
    output_dir = Path("percorso/della/cartella/risultati") # Cartella di destinazione per le immagini selezionate
    output_dir.mkdir(exist_ok=True)
    grafici_dir = Path("percorsa/della/cartella/grafici") # Cartella di destinazione per i grafici
    grafici_dir.mkdir(exist_ok=True)
    ```
3. Eseguire lo script `SelezioneImmaginiCosenoDistribuito.py` per selezionare le immagini.
4. La cartella di output `output_dir` avrÃ  questa struttura:
    ```
    nome_cartella
   â”œâ”€â”€ AI
   â”‚   â”œâ”€â”€ new_AI_LD_art_nouveau
   â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”‚   â”œâ”€â”€ ...
   â”‚   â”‚   â””â”€â”€ 0000xxxx.jpg
   â”‚   â”œâ”€â”€ new_AI_LD_baroque
   â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”‚   â”œâ”€â”€ ...
   â”‚   â”‚   â””â”€â”€ 0000xxxx.jpg
   â”‚   â”œâ”€â”€ ecc...
   â”œâ”€â”€ REAL
   â”‚   â”œâ”€â”€ new_art_nouveau
   â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”‚   â”œâ”€â”€ ...
   â”‚   â”‚   â””â”€â”€ 0000xxxx.jpg
   â”‚   â”œâ”€â”€ new_baroque
   â”‚   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”‚   â”œâ”€â”€ ...
   â”‚   â”‚   â””â”€â”€ 0000xxxx.jpg
   â”‚   â”œâ”€â”€ ecc...
    ```

## ðŸ“Š Creazione del dataset per il training
1. File interessato: `build_dataset.py`
2. Variabili interresate: `base_dir`, `output_base_dir`, `output_base_dir_real`
1. Aggiornare il valore di `base_dir` con il percorso della cartella creata dallo script precedente. Inoltre, modificare le variabili `output_base_dir` e `output_base_dir_real` aggiungendo i path delle cartelle di output.
   - Esempio:
    ```python
   # Cartella contenente le immagini selezionate 
   base_dir = Path("percorso/della/cartella/risultati")  # Cartella contenente le immagini selezionate
   # Cartelle di destinazione per i dataset
   output_base_dir = Path("DatasetTraining(NotProcessed)/AI")  # Cartella di destinazione per AI
   output_base_dir_real = Path("DatasetTraining(NotProcessed)/REAL")  # Cartella di destinazione per REAL
    ```
2. Eseguire lo script `build_dataset.py` per creare il dataset per il training.
3. Le cartelle di output avranno questa struttura:
    ```
    DatasetTraining(NotProcessed)
   â”œâ”€â”€ AI
   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”œâ”€â”€ ...
   â”‚   â””â”€â”€ 0000xxxx.jpg
   â”œâ”€â”€ REAL
   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”œâ”€â”€ ...
   â”‚   â””â”€â”€ 0000xxxx.jpg
   ```
> **Nota:** Per evitare confusione, si consiglia di aggiungere l'etichetta (NotProcessed) alle cartelle di output. In questa fase, le immagini non sono ancora utilizzabili dal modello, poichÃ© non rispettano la dimensione di 224 x 224 pixel richiesta. Al momento, le immagini sono ancora 256 x 256 pixel. Il nome `DatasetTraining(NotProcessed)` Ã¨ da considerare come placeholder.

## ðŸ–¼ï¸ Preprocessing delle immagini
1. File interessati: `data_preprocess.py`
2. Variabili interessate: `processed_path` ,`input_real_path`,`input_ai_path`
3. Aggiungere path alle variabile
4. i`processed_path`,`input_real_path`,`input_ai_path`
      ```python
    def create_output_folders(base_path):
    processed_path = os.path.join(base_path, "cartella_di_destinazione(Processed)") #cartella di output dove ci saranno le immagini processate
    ai_path = os.path.join(processed_path, "AI") #cartella interna a processed_path
    real_path = os.path.join(processed_path, "REAL") #cartella interna a processed_path
   
    os.makedirs(ai_path, exist_ok=True)
    os.makedirs(real_path, exist_ok=True)
   
    return ai_path, real_path
      ```
4. Variabili interessate: `input_real_path`,`input_ai_path`
5. Aggiungere path alla variabile `input_real_path`,`input_ai_path` (Sostituire `nome_cartella(NotProcessed)` con il nome della cartella in output dallo script precedente)
   ```python
   if __name__ == "__main__":
    base_path = os.path.dirname(os.path.abspath(__file__))
    input_ai_path = os.path.join(base_path, "nome_cartella(NotProcessed)", "AI") #cartella AI dentro nome_cartella(NotProcessed)
    input_real_path = os.path.join(base_path, "nome_cartella(NotProcessed)", "REAL") #cartella REAL dentro nome_cartella(NotProcessed)
    ```
2. Eseguire lo script `data_preprocess.py` per preprocessare le immagini.
3. Le cartelle di output avranno questa struttura:
    ```
    cartella_di_destinazione(Processed)
   â”œâ”€â”€ AI
   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”œâ”€â”€ ...
   â”‚   â””â”€â”€ 0000xxxx.jpg
   â”œâ”€â”€ REAL
   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”œâ”€â”€ ...
   â”‚   â””â”€â”€ 0000xxxx.jpg
   ```
> **Nota:** Le immagini sono state ridimensionate a 224 x 224 pixel e sono ora pronte per il training. Ãˆ possibile modificare i percorsi delle cartelle di destinazione tramite le variabili `ai_path` e `real_path`; tuttavia, questa operazione Ã¨ fortemente sconsigliata, in quanto richiederebbe ulteriori modifiche agli script per garantirne il corretto funzionamento.

## ðŸ§ª Creazione del TestSet
1. File interessati: `build_testset.py`
2. Variabili interessate: `base_dir`, `output_base_dir` e `output_base_dir_real`
3. Aggiungere path alle cartelle `base_dir`, `output_base_dir` e `output_base_dir_real`
    ```python
   # Cartella contenente le immagini selezionate 
   base_dir = Path("percorso_della_cartella_test ES: ../../real-ai-art/test")  # Cartella contenente le immagini per il test
   # Cartelle di destinazione per le immagini di test
   output_base_dir = Path("cartella_test/AI_test ES: TestSet/AI_test")  # Cartella di destinazione per AI
   output_base_dir_real = Path("cartella_test/REAL_test ES: TestSet/REAL_test")  # Cartella di destinazione per REAL
    ```
2. Eseguire lo script `build_testset.py` per creare la cartella di test.
3. La cartella di output avrÃ  questa struttura:
    ```
    TestSet
   â”œâ”€â”€ AI_test
   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”œâ”€â”€ ...
   â”‚   â””â”€â”€ 0000xxxx.jpg
   â”œâ”€â”€ REAL_test
   â”‚   â”œâ”€â”€ 00000001.jpg
   â”‚   â”œâ”€â”€ 00000002.jpg
   â”‚   â”œâ”€â”€ ...
   â”‚   â””â”€â”€ 0000xxxx.jpg
    ```

## ï¸ðŸ‹ï¸â€â™‚ï¸ Training del modello

1. Modificare i valori delle variabili `dataset_dir`, `test_dir` e `output_dir` nel file `main.py` per specificare i percorsi delle cartelle di input e di output.
    ```python
   def main():
    # Definisci i percorsi delle cartelle
    dataset_dir = ""  # Sostituisci con il percorso del dataset ES: "DatasetTraining(Processed)"
    test_dir = ""   # Sostituisci con il percorso della cartella di test ES: "Test"
    output_dir = ""         # Sostituisci con il percorso della cartella di output dove salvare i risultati ES: 'modello/nuovo/'
    ```
2. Eseguire lo script `main.py` per avviare il training del modello.
3. I risultati del training saranno salvati nella cartella di output specificata `output_dir`.
4. Il modello addestrato sarÃ  salvato come `model.h5` nella cartella di output.
5. I risultati del training saranno salvati come grafici nella cartella di output.
6. I risultati del training includono:
    - Grafico dell'accuratezza e specificity
    - Grafico della loss
    - Grafico della matrice di confusione
    - Grafico della curva ROC
    - Grafico precision, recall, accuracy, specificity

# ðŸ”„ Ordine di esecuzione degli script
1. `SelezioneImmaginiCosenoDistribuito.py`
2. `build_dataset.py`
3. `data_preprocess.py`
4. `build_testset.py`
5. `main.py`


> Se si Ã¨ scelto di usare il Dataset giÃ  processato, Ã¨ necessario solo il passaggio n.5

## ðŸŒ Esecuzione dell'interfaccia

Per avviare l'interfaccia web di **SGARB-AI**, segui questi passaggi:

1. Apri un terminale o prompt dei comandi.
2. Naviga alla cartella `/interface` del progetto:
    ```bash
    cd /percorso/del/progetto/interface
    ```
3. Esegui il file `app.py` utilizzando Python:
    ```bash
    python app.py
    ```
4. Una volta avviato, il terminale mostrerÃ  un messaggio simile a questo:
    ```
    * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
    ```
5. Apri un browser e vai all'indirizzo [http://127.0.0.1:5000](http://127.0.0.1:5000). Visualizzerai l'interfaccia grafica del progetto.

> **Nota:** Assicurati che tutte le dipendenze richieste per il progetto siano installate e che l'ambiente virtuale sia attivo.

